# Clasificaci√≥n de Modulaciones usando una CNN en una FPGA Pynq-Z2

<p align="center" style:"display:">
  <img src="img/hls4ml.png" alt="hls4ml Logo" width="200" style="margin-right: 20px;" />
  <img src="img/pynq.png" alt="PYNQ Logo" width="200" />
</p>

Este proyecto ha sido desarrollado como parte del **M√°ster Universitario en Ingenier√≠a en Tecnolog√≠as de Telecomunicaci√≥n** de la **Universidad de Granada (UGR)**.

El objetivo principal es el estudio, an√°lisis y clasificaci√≥n autom√°tica de se√±ales de radiofrecuencia (RF) utilizando t√©cnicas de **Deep Learning** (Redes Neuronales Convolucionales - CNN). Adem√°s, el proyecto abarca la implementaci√≥n y despliegue de estos modelos en hardware reconfigurable (**FPGA**) utilizando herramientas de s√≠ntesis de alto nivel como **hls4ml** para la placa **PYNQ-Z2**.

## üìã Descripci√≥n

El proyecto se divide en tres bloques fundamentales:

1.  **Visualizaci√≥n y An√°lisis de Datos**: Herramientas para inspeccionar el dataset RadioML 2016.10a, visualizando constelaciones IQ, formas de onda y espectros de potencia.
2.  **Entrenamiento de Modelos**: Scripts para entrenar redes neuronales (CNN) capaces de clasificar esquemas de modulaci√≥n (BPSK, QPSK, 8PSK, etc.) bajo distintas condiciones de ruido (SNR).
3.  **Despliegue en FPGA**: Flujo de trabajo completo para convertir los modelos entrenados en Keras a IP cores de hardware (HLS) y generar el bitstream para aceleraci√≥n en FPGA.

## üõ†Ô∏è Requisitos y Tecnolog√≠as

El proyecto utiliza **Python 3.14** (gestionado v√≠a Poetry) y las siguientes librer√≠as clave:

*   **TensorFlow / Keras**: Construcci√≥n y entrenamiento de redes neuronales.
*   **hls4ml**: Conversi√≥n de modelos de Machine Learning a HLS para FPGAs.
*   **Numpy / Scipy**: Procesamiento num√©rico de se√±ales.
*   **Matplotlib / Plotly**: Visualizaci√≥n de datos y resultados.

### Requisitos del Sistema (para s√≠ntesis FPGA)
*   **Xilinx Vivado (2019.2 o 2020.1 recomendado)**: Necesario para la s√≠ntesis y generaci√≥n del bitstream si se ejecuta el flujo de hardware.

## üöÄ Instalaci√≥n

Este proyecto utiliza **Poetry** para la gesti√≥n de dependencias, asegurando un entorno reproducible.

1.  **Clonar el repositorio:**
    ```bash
    git clone <url-del-repositorio>
    cd Proyecto_final
    ```

2.  **Instalar dependencias:**
    ```bash
    poetry install
    ```

3.  **Dataset:**
    Aseg√∫rate de tener el archivo del dataset `RML2016.10a_dict.dat` (o `RML2016.10a_dict_v1.dat`) en la ra√≠z del proyecto. Este dataset contiene las se√±ales IQ etiquetadas.

## üìñ Uso y Funcionalidades

### 1. Visualizaci√≥n de Se√±ales (`plot_iq.py` y `plot_waveforms.py`)

Estos scripts permiten explorar visualmente el dataset para entender la naturaleza de las se√±ales RF.

*   **Diagramas de Constelaci√≥n y Espectro:**
    ```bash
    poetry run python plot_iq.py
    ```
    *Genera gr√°ficos de la constelaci√≥n IQ y el espectro de potencia para una modulaci√≥n y SNR espec√≠ficos.*

*   **Formas de Onda en el Tiempo:**
    ```bash
    poetry run python plot_waveforms.py
    ```
    *Muestra las componentes I (In-phase) y Q (Quadrature) en el dominio del tiempo para vectores seleccionados.*

### 2. Entrenamiento del Modelo (`modeloentrenamiento.py`)

Entrena una CNN completa (basada en la arquitectura VT-CNN2) sobre todo el conjunto de modulaciones disponibles en el dataset.

```bash
poetry run python modeloentrenamiento.py
```
*   **Salida**: Guarda el modelo entrenado como `modelo_final_pynq.h5` y los pesos √≥ptimos en `cnn2_best_weights.h5`.
*   Genera gr√°ficas de precisi√≥n (accuracy) vs SNR y matrices de confusi√≥n.

### 3. Optimizaci√≥n y Despliegue en FPGA

Para llevar el modelo a una FPGA (PYNQ-Z2), utilizamos un flujo especializado que incluye cuantizaci√≥n y s√≠ntesis.

#### A. Entrenamiento Optimizado para FPGA (`redneuoronal_optima.py`)
Entrena una versi√≥n m√°s ligera y eficiente del modelo, optimizada para hardware (menos par√°metros, subset de modulaciones).
```bash
poetry run python redneuoronal_optima.py
```
*   **Salida**: `model_fpga.h5`.

#### B. Conversi√≥n y Generaci√≥n de Bitstream (`hls4mlVivadoacelerator.py`)
Este es el script maestro para el flujo de hardware. Realiza las siguientes tareas:
1.  Carga y prepara los datos.
2.  Entrena/Carga el modelo.
3.  Configura `hls4ml` para usar la estrategia de latencia y precisi√≥n `ap_fixed<16,6>`.
4.  Ejecuta la s√≠ntesis con Vivado para generar el **Bitstream** (`.bit`) y el **Hardware Handoff** (`.hwh`).

```bash
poetry run python hls4mlVivadoacelerator.py
```
> **Nota:** Este proceso requiere tener Vivado instalado y en el PATH. Puede tardar entre 15 y 45 minutos.

## üìÇ Estructura del Proyecto

*   `plot_iq.py`: Visualizaci√≥n de constelaciones y espectros.
*   `plot_waveforms.py`: Visualizaci√≥n de se√±ales en el tiempo.
*   `modeloentrenamiento.py`: Entrenamiento de la CNN principal (Software baseline).
*   `redneuoronal_optima.py`: Entrenamiento de la CNN optimizada para FPGA.
*   `hls4mlVivadoacelerator.py`: Script "End-to-End" para generar el acelerador hardware (IP Core + Bitstream).
*   `conversionHls4ml.py`: Script auxiliar de conversi√≥n HLS (alternativo).
*   `RML2016.10a_dict.dat`: Dataset de entrada.
*   `pyproject.toml`: Configuraci√≥n de dependencias (Poetry).

## üéì Autores y Cr√©ditos

**Autor:** Rodrigo Garc√≠a Le√≥n, Luc√≠a Fern√°ndez Carrascosas, Guillermo Albacete Fuentes.
**M√°ster:** M√°ster Universitario en Ingenier√≠a de Telecomunicaci√≥n  
**Universidad:** Universidad de Granada (UGR)  
**Asignatura:** Sistemas Electr√≥nicos Integrados

---
*Este proyecto utiliza el dataset RadioML 2016.a basado en el trabajo de Tim O'Shea*
